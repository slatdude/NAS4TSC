{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_dZSTn_1Y4I",
        "outputId": "a0dc6f9e-e646-4800-f254-fae04f509290"
      },
      "outputs": [],
      "source": [
        "!pip install tsai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h8ARjtc15Av"
      },
      "source": [
        "需要修改一下/usr/local/lib/python3.7/dist-packages/tsai-0.2.26-py3.7.egg/tsai/models/utils.py这里的内容。添加一个NewModel或者之类的东西。再次手动增加内容。\n",
        "后续可以考虑添加对应的包，直接在安装的时候成功。\n",
        "同时如果针对LSTM-FCN，需要添加一个参数输入的内容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjJa35ssMbPK",
        "outputId": "be1b25e9-c858-4569-8306-3663f76111bb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Thesis_exp')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOqI8ZXK2IZp",
        "outputId": "0bb20ea9-d997-40e4-a2a5-ab62f0876e1a"
      },
      "outputs": [],
      "source": [
        "from tsai.all import *\n",
        "import os\n",
        "computer_setup()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LllNSVKNU7Jg"
      },
      "outputs": [],
      "source": [
        "# coding:UTF-8\n",
        "# V2, ResNet Imporve\n",
        "# V2.1, Change the built_layer method. \n",
        "\n",
        "\n",
        "from tsai.imports import *\n",
        "from tsai.utils import *\n",
        "from torch.nn.init import normal_\n",
        "from fastai.torch_core import Module\n",
        "from fastai.layers import *\n",
        "from torch.nn.utils import weight_norm, spectral_norm\n",
        "\n",
        "Convolution = [8, 16, 32, 64, 128, 256]\n",
        "# ZeroOp, 默认\n",
        "# MaxPooling, 默认\n",
        "# Dropout, 0-0.5之间\n",
        "# Activate = {1: 'softmax', 2: 'elu', 3: 'Relu', 4: 'selu', 5: 'sigmoid'}\n",
        "Activate = ['softmax', 'elu', 'Relu', 'selu', 'sigmoid']\n",
        "Dense = [8, 16, 32, 64, 128, 256]\n",
        "\n",
        "\n",
        "\n",
        "from tsai.imports import *\n",
        "from tsai.utils import *\n",
        "from torch.nn.init import normal_\n",
        "from fastai.torch_core import Module\n",
        "from fastai.layers import *\n",
        "from torch.nn.utils import weight_norm, spectral_norm\n",
        "\n",
        "\n",
        "# DenseBlock\n",
        "class DenseBlock(nn.Sequential):\n",
        "    \"Create a sequence of conv1d (`ni` to `nf`), activation (if `act_cls`) and `norm_type` layers.\"\n",
        "    def __init__(self, cin, cout, **kwargs):\n",
        "        layers = []\n",
        "        layers += nn.Linear(cin, cout)\n",
        "        layers += nn.ReLU()\n",
        "        super().__init__(*layers)\n",
        "        # 找到此时ConvBlock的父类Sequential, 随后调用它的初始化函数\n",
        "\n",
        "\n",
        "\n",
        "class NewModel(Module):\n",
        "    def __init__(self, c_in, c_out, seq_len=None, hidden_size=100, rnn_layers=1, bias=True, cell_dropout=0,\n",
        "                 rnn_dropout=0.8, bidirectional=False, shuffle=True,\n",
        "                 fc_dropout=0., conv_layers=[128, 256, 128], kss=[7, 5, 3], se=0, Phenotype=[]):\n",
        "        if shuffle: assert seq_len is not None, 'need seq_len if shuffle=True'\n",
        "\n",
        "        # RNN\n",
        "        front_output = conv_layers[2]\n",
        "        self.rnn = nn.LSTM(seq_len if shuffle else c_in, hidden_size, num_layers=rnn_layers, bias=bias,\n",
        "                              batch_first=True,\n",
        "                              dropout=cell_dropout, bidirectional=bidirectional)\n",
        "        self.rnn_dropout = nn.Dropout(rnn_dropout) if rnn_dropout else noop\n",
        "        self.shuffle = Permute(0, 2,\n",
        "                               1) if not shuffle else noop  # You would normally permute x. Authors did the opposite.\n",
        "        print(seq_len)\n",
        "        # FCN，主要解决下方cnn部分的内容\n",
        "        assert len(conv_layers) == len(kss)\n",
        "\n",
        "        # 卷积之后，再加一层池化、激活函数\n",
        "        self.convblock1 = ConvBlock(c_in, conv_layers[0], kss[0])\n",
        "        self.se1 = SqueezeExciteBlock(conv_layers[0], se) if se != 0 else noop\n",
        "\n",
        "        self.convblock2 = ConvBlock(conv_layers[0], conv_layers[1], kss[1])\n",
        "        self.se2 = SqueezeExciteBlock(conv_layers[1], se) if se != 0 else noop\n",
        "\n",
        "        self.convblock3 = ConvBlock(conv_layers[1], conv_layers[2], kss[2])\n",
        "\n",
        "        # Added_layer\n",
        "        self.layer_list = []\n",
        "        # print(len(Phenotype))\n",
        "        for i in range(len(Phenotype)):\n",
        "            layer, front_output = self._make_layer(Phenotype[i], front_output)\n",
        "            # 如果ZeroOP\n",
        "            if layer == 0:\n",
        "                continue\n",
        "            self.layer_list.append(layer)\n",
        "        \n",
        "        # print(self.layer_list)\n",
        "\n",
        "        self.net = nn.Sequential(*self.layer_list)\n",
        "\n",
        "        self.gap = GAP1d(1)\n",
        "\n",
        "        # Common\n",
        "        self.concat = Concat()\n",
        "        self.fc_dropout = nn.Dropout(fc_dropout) if fc_dropout else noop\n",
        "        self.fc = nn.Linear(hidden_size * (1 + bidirectional) + front_output, c_out)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        # RNN\n",
        "        rnn_input = self.shuffle(x)  # permute --> (batch_size, seq_len, n_vars) when batch_first=True\n",
        "        output, _ = self.rnn(rnn_input)\n",
        "        last_out = output[:, -1]  # output of last sequence step (many-to-one)\n",
        "        last_out = self.rnn_dropout(last_out)\n",
        "\n",
        "        # FCN\n",
        "        x = self.convblock1(x)\n",
        "        x = self.se1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.se2(x)\n",
        "        x = self.convblock3(x)\n",
        "        # print(\"Befor New Layers: \", x.shape)\n",
        "\n",
        "        # x = self.net(x)\n",
        "        for operator in self.net:\n",
        "            if isinstance(operator, nn.Linear):\n",
        "                x = torch.transpose(x, 1, 2)\n",
        "                x = operator(x)\n",
        "                x = torch.transpose(x, 1, 2)\n",
        "            else:\n",
        "                x = operator(x)\n",
        "            # print(f\"After a New Layer {operator}:\", x.shape)\n",
        "        \n",
        "        x = self.gap(x)\n",
        "\n",
        "        # Concat\n",
        "        x = self.concat([last_out, x])\n",
        "        x = self.fc_dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    \n",
        "    def _make_layer(self, Phenotype, front_output):\n",
        "        # Make layer by Phenotype\n",
        "        if Phenotype[0] == 0:  # conv\n",
        "            out_size = Convolution[int(Phenotype[1])]            \n",
        "            return ConvBlock(front_output, out_size, 3), out_size\n",
        "        \n",
        "        elif Phenotype[0] == 1:  # ZeroOp\n",
        "            return 0, front_output\n",
        "\n",
        "        elif Phenotype[0] == 2:  # Maxpooling, Pooling size = 3, zero padding.\n",
        "            return nn.MaxPool1d(kernel_size=3, stride=1, padding=1), front_output\n",
        "\n",
        "        elif Phenotype[0] == 3:  # Dropout\n",
        "            dropout_rate = Phenotype[1]\n",
        "            return nn.Dropout(dropout_rate), front_output\n",
        "\n",
        "        elif Phenotype[0] == 4: # Activate\n",
        "            if Phenotype[1] == 0:\n",
        "                act = nn.Softmax()\n",
        "            elif Phenotype[1] == 1:\n",
        "                act = nn.ELU()\n",
        "            elif Phenotype[1] == 2:\n",
        "                act = nn.ReLU()\n",
        "            elif Phenotype[1] == 3:\n",
        "                act = nn.SELU()\n",
        "            elif Phenotype[1] == 4:\n",
        "                act = nn.Sigmoid()\n",
        "            return act, front_output\n",
        "\n",
        "        elif Phenotype[0] == 5: # FC\n",
        "            out_size = Dense[int(Phenotype[1])]\n",
        "            return nn.Linear(front_output, out_size), out_size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AFR8dqBf6pjd",
        "outputId": "510b4b87-f13b-489b-aee4-8f272a682655"
      },
      "outputs": [],
      "source": [
        "# coding:UTF-8\n",
        "# V2, LSTM-FCN Imporve\n",
        "# 3.11.2022 run data, GPU\n",
        "\n",
        "from __future__ import division\n",
        "from numpy import *\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "NP = 10\n",
        "size = 15\n",
        "xMin = -10\n",
        "xMax = 10\n",
        "F = 0.8\n",
        "CR = 0.5\n",
        "LAYER_THRESHOLD = 0.9\n",
        "GEN_MAX = 10\n",
        "TRAIN_EPOCHES = 100\n",
        "\n",
        "# 神经结构的参数设置\n",
        "Convolution = [8, 16, 32, 64, 128, 256]\n",
        "# ZeroOp, 默认\n",
        "# MaxPooling, 默认\n",
        "# Dropout, 0-0.5之间\n",
        "# Activate = {1: 'softmax', 2: 'elu', 3: 'Relu', 4: 'selu', 5: 'sigmoid'}\n",
        "Activate = ['softmax', 'elu', 'Relu', 'selu', 'sigmoid']\n",
        "Dense = [8, 16, 32, 64, 128, 256]\n",
        "\n",
        "\n",
        "\n",
        "# all_dataset = ['ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', \n",
        "#                'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken', 'BME', 'Car', 'CBF', 'Chinatown', \n",
        "#                'ChlorineConcentration', 'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY', \n",
        "#                'CricketZ', 'Crop', 'DiatomSizeReduction', 'DistalPhalanxOutlineAgeGroup', \n",
        "#                'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame', \n",
        "#                'DodgerLoopWeekend', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays', 'ElectricDevices', \n",
        "#                'EOGHorizontalSignal', 'EOGVerticalSignal', 'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', \n",
        "#                'FiftyWords', 'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain', 'Fungi', \n",
        "#                'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', \n",
        "#                'GunPoint', 'GunPointAgeSpan', 'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham', \n",
        "#                'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate', 'InsectEPGRegularTrain', \n",
        "#                'InsectEPGSmallTrain', 'InsectWingbeatSound', 'ItalyPowerDemand', 'LargeKitchenAppliances', \n",
        "#                'Lightning2', 'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian', \n",
        "#                'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxTW', \n",
        "#                'MixedShapesRegularTrain', 'MixedShapesSmallTrain', 'MoteStrain', 'NonInvasiveFetalECGThorax1', \n",
        "#                'NonInvasiveFetalECGThorax2', 'OliveOil', 'OSULeaf', 'PhalangesOutlinesCorrect', 'Phoneme', \n",
        "#                'PickupGestureWiimoteZ', 'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'PLAID', 'Plane', \n",
        "#                'PowerCons', 'ProximalPhalanxOutlineAgeGroup', 'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', \n",
        "#                'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2', 'SemgHandMovementCh2', \n",
        "#                'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ', 'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', \n",
        "#                'SmoothSubspace', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarLightCurves', 'Strawberry', \n",
        "#                'SwedishLeaf', 'Symbols', 'SyntheticControl', 'ToeSegmentation1', 'ToeSegmentation2', 'Trace', \n",
        "#                'TwoLeadECG', 'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX', \n",
        "#                'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine', 'WordSynonyms', 'Worms', \n",
        "#                'WormsTwoClass', 'Yoga']\n",
        "\n",
        "\n",
        "# 完成的数据集: 'ACSF1', 'Adiac', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken', 'BME', 'Car', 'CBF', 'Chinatown', 'ChlorineConcentration', \n",
        "#             'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY', 'CricketZ', 'DiatomSizeReduction', 'DistalPhalanxOutlineAgeGroup', \n",
        "#             'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW','Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays', 'EOGHorizontalSignal', \n",
        "#             'EOGVerticalSignal', 'EthanolLevel','FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords', 'Fish', 'FordA', 'FreezerRegularTrain', 'FreezerSmallTrain', 'Fungi', \n",
        "#             'GunPoint','GunPointAgeSpan', 'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham', \n",
        "#             'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate', 'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound', 'ItalyPowerDemand', 'LargeKitchenAppliances',             \n",
        "#             'Lightning2', 'Lightning7', 'Mallat', 'Meat', 'MedicalImages',  'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect',  'MiddlePhalanxTW',  \n",
        "#             'MixedShapesRegularTrain', 'MixedShapesSmallTrain', 'MoteStrain', 'NonInvasiveFetalECGThorax1','OliveOil', 'OSULeaf', 'PhalangesOutlinesCorrect', 'Phoneme', \n",
        "#             'PigAirwayPressure', 'PigArtPressure', 'PigCVP',  'Plane', 'PowerCons', 'ProximalPhalanxOutlineAgeGroup', 'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', \n",
        "#             'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2', 'SemgHandMovementCh2', 'SemgHandSubjectCh2', \n",
        "#             'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'Strawberry', \n",
        "#             'SwedishLeaf', 'Symbols', 'SyntheticControl', 'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG', 'TwoPatterns', 'UMD',\n",
        "#             'UWaveGestureLibraryX', 'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine', 'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga'\n",
        "#             'AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', 'DodgerLoopDay', 'DodgerLoopGame', 'DodgerLoopWeekend', \n",
        "#             'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', 'PickupGestureWiimoteZ', 'PLAID',\n",
        "#             'ShakeGestureWiimoteZ', 'MelbournePedestrian',            \n",
        "#             'Crop', 'ElectricDevices', 'FordB', 'NonInvasiveFetalECGThorax2', 'StarLightCurves', 'UWaveGestureLibraryAll', \n",
        "#             \n",
        "#             \n",
        "# 异常数据集:    'AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', 'DodgerLoopDay', 'DodgerLoopGame', 'DodgerLoopWeekend', \n",
        "#              'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', 'PickupGestureWiimoteZ', 'PLAID',\n",
        "#              'ShakeGestureWiimoteZ', 'MelbournePedestrian',\n",
        "#           \n",
        "# 运算比较久的数据集: 'Crop', 'ElectricDevices', 'FordB', 'NonInvasiveFetalECGThorax2', 'StarLightCurves', 'UWaveGestureLibraryAll', \n",
        "\n",
        "\n",
        "dataset_with_nan = ['AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', 'DodgerLoopDay', 'DodgerLoopGame', 'DodgerLoopWeekend', \n",
        "             'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', 'PickupGestureWiimoteZ', 'PLAID',\n",
        "             'ShakeGestureWiimoteZ', 'MelbournePedestrian',]\n",
        "\n",
        "\n",
        "# all_dataset = ['Crop', 'ElectricDevices', 'FordB', 'NonInvasiveFetalECGThorax2', 'StarLightCurves', 'UWaveGestureLibraryAll']\n",
        "all_dataset = ['Crop']\n",
        "\n",
        "\n",
        "# 优点：可以并行计算，可以模拟nature中的进化规律，获得constraint 之外的结构\n",
        "\n",
        "\n",
        "# 翻译此时的结构\n",
        "def translate_architecture(Individual, display=False):\n",
        "    m, n = shape(Individual)\n",
        "    Actual_structure = zeros((m, n))\n",
        "    layers = []\n",
        "    # 15 * 2\n",
        "    for i in range(m):\n",
        "        # Conv layer\n",
        "        if Individual[i][0] == 0:\n",
        "            single_layer = [\"conv\"]\n",
        "            single_layer.append(Convolution[int(Individual[i][1] * 6)])\n",
        "            Actual_structure[i] = [Individual[i][0], int(Individual[i][1] * 6)]\n",
        "        # ZeroOp layer\n",
        "        elif Individual[i][0] == 1:\n",
        "            single_layer = [\"ZeroOp\"]\n",
        "            single_layer.append(\"Default\")\n",
        "            Actual_structure[i] = [Individual[i][0], Individual[i][1]]\n",
        "        # Maxpooling layer\n",
        "        elif Individual[i][0] == 2:\n",
        "            single_layer = [\"Maxpooling\"]\n",
        "            single_layer.append(\"Default\")\n",
        "            Actual_structure[i] = [Individual[i][0], Individual[i][1]]\n",
        "        # Dropout layer\n",
        "        elif Individual[i][0] == 3:\n",
        "            single_layer = [\"Dropout\"]\n",
        "            single_layer.append(0.5*Individual[i][1])\n",
        "            Actual_structure[i] = [Individual[i][0], 0.5*Individual[i][1]]\n",
        "        # Activate layer\n",
        "        elif Individual[i][0] == 4:\n",
        "            single_layer = [\"Activate\"]\n",
        "            single_layer.append(Activate[int(Individual[i][1] * 5)])\n",
        "            Actual_structure[i] = [Individual[i][0], int(Individual[i][1] * 5)]\n",
        "        # Dense layer\n",
        "        elif Individual[i][0] == 5:\n",
        "            single_layer = [\"Dense\"]\n",
        "            single_layer.append(Dense[int(Individual[i][1] * 6)])\n",
        "            Actual_structure[i] = [Individual[i][0], int(Individual[i][1] * 6)]\n",
        "        layers.append(single_layer)\n",
        "    if display:\n",
        "        print(f\"structure is {layers}\")\n",
        "    return Actual_structure\n",
        "\n",
        "\n",
        "def checkifweak(Individual):\n",
        "    # 判断此时是否已经是弱基因\n",
        "    # Add basic constraint\n",
        "\n",
        "    m, n = shape(Individual)\n",
        "    for i in range(m - 1):\n",
        "        # 如果此时是两个连续的下采样就返回true\n",
        "        if Individual[i][0] == 2 and Individual[i + 1][0] == 2:\n",
        "            return True\n",
        "        # 如果此时是两个连续的激活函数就返回True\n",
        "        elif Individual[i][0] == 4 and Individual[i + 1][0] == 4:\n",
        "            return True\n",
        "        # 如果此时是两个相邻的FCN，同时有一个降维特别大，就返回True\n",
        "        elif Individual[i][0] == 5 and Individual[i + 1][0] == 5:\n",
        "            if Individual[i][1] < 0.5 or Individual[i + 1][1] < 0.5:\n",
        "              return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# 通过此时的基因型获取模型\n",
        "def GetModel(Phenotype, dls):    \n",
        "    m, n = shape(Phenotype)\n",
        "    arch = NewModel\n",
        "    model = create_model(arch, dls=dls, Phenotype=Phenotype)\n",
        "    # arch = LSTM_FCN\n",
        "    # model = create_model(arch, dls=dls)\n",
        "    print(arch.__name__)\n",
        "    print(model)\n",
        "    return model\n",
        "\n",
        "\n",
        "# 获取单个个体的基因型对应的适应度(Pred)\n",
        "def getPred(Phenotype, dls):\n",
        "    \n",
        "    # 训练\n",
        "    model = GetModel(Phenotype, dls)\n",
        "    \n",
        "    learn = Learner(dls, model,  metrics=accuracy)\n",
        "    start = time.time()\n",
        "    learn.fit_one_cycle(TRAIN_EPOCHES, 1e-3)\n",
        "    elapsed = time.time() - start\n",
        "    vals = learn.recorder.values[-1]\n",
        "    print(f\"训练耗时:{int(elapsed)}\")\n",
        "    # vals 的结构：val[3] = [\"train loss\", \"valid loss\", \"accuracy\"]\n",
        "    return vals[2]\n",
        "    # return 1\n",
        "\n",
        "\n",
        "# 计算适应值函数\n",
        "def calFitness(Individual, dls):\n",
        "    # Translate Individual Architecture\n",
        "    # 目标: pred\n",
        "    # Phenotype = translate_architecture(Individual, display=True)\n",
        "    Phenotype = translate_architecture(Individual)\n",
        "    fitness = getPred(Phenotype, dls)\n",
        "    return fitness\n",
        "\n",
        "\n",
        "# 变异函数\n",
        "def mutation(X_Parent, F, LAYER_THRESHOLD):\n",
        "    # Mutate for Neural network\n",
        "    print(shape(X_Parent))\n",
        "    m, n, k = shape(X_Parent)\n",
        "    # print()\n",
        "    XMutationTmp = zeros((m, n, k))\n",
        "\n",
        "    # 对于此时来说，需要额外设定一个layer_rate, 如果大于layer_rate，那么就mutate，layer，如果小于layer_rate，调整parameter。\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for i in range(m):\n",
        "      # 需要调整，此时的r1应该删掉，随后改成其他的\n",
        "        r1 = 0\n",
        "        r2 = 0\n",
        "        r3 = 0\n",
        "        while r1 == i or r2 == i or r3 == i or r1 == r2 or r1 == r3 or r2 == r3:\n",
        "            r1 = rd.randint(0, m - 1)\n",
        "            r2 = rd.randint(0, m - 1)\n",
        "            r3 = rd.randint(0, m - 1)\n",
        "\n",
        "        for j in range(n):\n",
        "            # 如果需要修改layer\n",
        "            layer_change = rd.random()\n",
        "            if (layer_change > LAYER_THRESHOLD):\n",
        "                changed_layer = rd.randint(0, 5)\n",
        "                XMutationTmp[i, j] = [changed_layer, rd.random()]\n",
        "                continue\n",
        "\n",
        "            # 如果不需要修改layer， 这里会有点担心会产生越界\n",
        "\n",
        "            # 首先要看一下此时是不是同一类的r1, r2, r3，因为真的太严格了，所以就是说mutate也要考虑基因突变\n",
        "            # 如果r1、r2都满足的话，就可以按照操作开始变换。\n",
        "            if X_Parent[r1, j, 0] == X_Parent[r2, j, 0] or X_Parent[r1, j, 0] == X_Parent[r3, j, 0]:\n",
        "                # 用6完成一次取余操作\n",
        "                XMutationTmp[i, j] = [X_Parent[r1, j, 0], (X_Parent[r1, j, 1] + F * (X_Parent[r2, j, 1] - X_Parent[r3, j, 1])) % 1]\n",
        "                # print(\"差分操作完成\", count)\n",
        "                # count += 1\n",
        "            else:\n",
        "                XMutationTmp[i, j] = X_Parent[i, j]\n",
        "    # print()\n",
        "    return XMutationTmp\n",
        "\n",
        "\n",
        "# 交叉函数\n",
        "def crossover(X_Parent, XMutationTmp, CR):\n",
        "    # Binomial strategy\n",
        "    # 按照CR crossrate完成修正增\n",
        "\n",
        "    m, n, k = shape(X_Parent)\n",
        "    X_Crossover = zeros((m, n, k))\n",
        "\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            r = rd.random()\n",
        "            if r <= CR:\n",
        "                X_Crossover[i, j] = XMutationTmp[i, j]\n",
        "            else:\n",
        "                X_Crossover[i, j] = X_Parent[i, j]\n",
        "    return X_Crossover\n",
        "\n",
        "\n",
        "# 选择函数\n",
        "def selection(X_Parent, XCrossover, fitnessVal, dls):\n",
        "    # 从母代和子代中选取最高适应度的个体\n",
        "    # 同时增加constraint机制，如果出现了低性状变异，就不需要测试其适应度\n",
        "\n",
        "    m, n, k = shape(X_Parent)\n",
        "    print(\"Parent_fitness:\", fitnessVal)\n",
        "    fitnessCrossOverVal = zeros((m, 1))\n",
        "    for i in range(m):\n",
        "        print(f\"第{i + 1}个变异个体\")\n",
        "\n",
        "        if checkifweak(XCrossover[i]):\n",
        "            print(\"子代个体基因型受限\")\n",
        "            print(\"Parent Better\")\n",
        "            continue\n",
        "\n",
        "        fitnessCrossOverVal[i, 0] = calFitness(XCrossover[i], dls)\n",
        "        if (fitnessCrossOverVal[i, 0] > fitnessVal[i, 0]):\n",
        "            print(\"Mutate better\")\n",
        "            for j in range(n):\n",
        "                X_Parent[i, j] = XCrossover[i, j]\n",
        "            fitnessVal[i, 0] = fitnessCrossOverVal[i, 0]\n",
        "        else:    \n",
        "            print(\"Parent Better\")\n",
        "    return X_Parent, fitnessVal\n",
        "\n",
        "\n",
        "# 保存最佳函数\n",
        "def saveBest(XTemp, fitnessVal, round, dataset, dls):\n",
        "    m = shape(fitnessVal)[0]\n",
        "    print(\"After selection\", fitnessVal)\n",
        "    tmp = 0\n",
        "    for i in range(1, m):\n",
        "        if (fitnessVal[tmp] < fitnessVal[i]):\n",
        "            tmp = i\n",
        "\n",
        "\n",
        "    print(\"Round Best:\")\n",
        "    print(fitnessVal[tmp][0])\n",
        "    best_individual_phenotype = translate_architecture(XTemp[tmp], display=True)\n",
        "\n",
        "    model = GetModel(best_individual_phenotype, dls)\n",
        "    \n",
        "    if not os.path.exists(\"./model\"):\n",
        "        os.makedirs(\"./model\") # 如果不存在目录figure_save_path，则创建\n",
        "\n",
        "    torch.save(model, f\"./model/{dataset}_{round}_{fitnessVal[tmp][0]}.pkl\")\n",
        "\n",
        "    if not os.path.exists(\"./genotype\"):\n",
        "        os.makedirs(\"./genotype\") # 如果不存在目录figure_save_path，则创建\n",
        "\n",
        "    np.save(f\"./genotype/{dataset}_{round}_{fitnessVal[tmp][0]}.pkl\", XTemp[tmp], allow_pickle=True)\n",
        "    \n",
        "    return fitnessVal[tmp][0]\n",
        "\n",
        "\n",
        "# Differential_Evolution_Algorithm\n",
        "def DEA(dsid, dls):\n",
        "    # 初始化\n",
        "    XTemp = zeros((NP, size, 2))\n",
        "    # 构造对应的NP = 50, 基因长度size = 15, 每个size里包含的一个超参数，长度为2\n",
        "\n",
        "    for i in range(NP):\n",
        "        \n",
        "        while(1):\n",
        "            for j in range(size):\n",
        "                # 初始化规则：对于每个XTemp[i, j]，[x, y]相当于初始化此时的类型x以及参数y\n",
        "                # Conv的类型:          0; Conv的参数: [8, 16, 32, 64, 128, 256]; 一共6个参数，在乘以对应比例后截取整数部\n",
        "                # ZeroOP的类型:        1; 没有参数\n",
        "                # Maxpooling的类型:    2; MaxPooling，没有参数\n",
        "                # Dropout的类型:       3; Dropout的参数: [0, 0.5]; random后乘以0.5\n",
        "                # Activate的类型:      4; Activate的参数: ['softmax', 'elu', 'Relu', 'selu', 'sigmoid']; 5个参数，random后乘比例\n",
        "                # Dense的类型:         5; Dense的参数: [4, 16, 32, 64, 128, 256]; 6个参数, random后乘比例。\n",
        "                type = rd.randint(0, 5)\n",
        "                XTemp[i, j] = [type, rd.random()]              \n",
        "            if checkifweak(XTemp[i]):\n",
        "                print(\"初始化不满足约束，重置当前基因型\")\n",
        "            else:\n",
        "                break\n",
        "        \n",
        "    print(\"完成初始化\")\n",
        "    print(XTemp)\n",
        "    \n",
        "\n",
        "    if not os.path.exists(\"./generation\"):\n",
        "        os.makedirs(\"./generation\") # 如果不存在目录figure_save_path，则创建\n",
        "        \n",
        "    for individual in range(NP):\n",
        "        np.save(f\"./generation/{dsid}_0_{individual}.pkl\", XTemp[individual], allow_pickle=True)\n",
        "        print(f\"保存成功 ./generation/{dsid}_0_{individual}.pkl\")\n",
        "\n",
        "\n",
        "    print(\"完成种群记录\")\n",
        "\n",
        "    \n",
        "    \n",
        "    # 计算初始适应值\n",
        "    fitnessVal = zeros((NP, 1))\n",
        "    for i in range(NP):\n",
        "        print(f\"第{i + 1}个个体\")\n",
        "        fitnessVal[i, 0] = calFitness(XTemp[i], dls)\n",
        "\n",
        "    acc_map = []\n",
        "    fitness_for_record = np.empty(shape=(NP, 1))\n",
        "\n",
        "    gen = 1\n",
        "    while gen <= GEN_MAX:\n",
        "        print(\"\")\n",
        "        print(f\"Generation {gen}\")\n",
        "        \n",
        "        # mutate完成\n",
        "        XMutationTmp = mutation(XTemp, F, LAYER_THRESHOLD)\n",
        "        print(\"Mutate 完成\")\n",
        "        # translate_architecture(XMutationTmp[0], display=True)\n",
        "\n",
        "        print(\"Crossover完成\")\n",
        "        XCrossover = crossover(XTemp, XMutationTmp, CR)\n",
        "        # translate_architecture(XCrossover[0], display=True)\n",
        "\n",
        "        # 保存每一代个体\n",
        "        if not os.path.exists(\"./generation\"):\n",
        "            os.makedirs(\"./generation\") # 如果不存在目录figure_save_path，则创建\n",
        "        \n",
        "        for individual in range(NP):\n",
        "            np.save(f\"./generation/{dsid}_{gen}_{individual}.pkl\", XCrossover[individual], allow_pickle=True)\n",
        "            print(f\"保存成功./generation/{dsid}_{gen}_{individual}.pkl\")\n",
        "        \n",
        "        print(\"完成种群记录\")\n",
        "\n",
        "        XTemp, fitnessVal = selection(XTemp, XCrossover, fitnessVal, dls)\n",
        "        print(\"Select完成\")\n",
        "        # calFitness(XCrossover[0])\n",
        "        best_acc = saveBest(XTemp, fitnessVal, gen, dsid, dls)\n",
        "\n",
        "        acc_map.append(best_acc)\n",
        "        # fitness_for_record.append(fitnessVal)\n",
        "        fitness_for_record = np.append(fitness_for_record, fitnessVal, axis=1)\n",
        "\n",
        "        print(fitness_for_record)\n",
        "        test = pd.DataFrame(data=fitness_for_record)\n",
        "        # print(\"以下是原始数据\")\n",
        "        # print(test)\n",
        "        test.to_csv(f'./{dsid}_raw_data.csv',encoding='gbk')\n",
        "        \n",
        "        gen += 1\n",
        "    print(f\"Dataset{dsid} detail:\")\n",
        "    print(fitness_for_record)\n",
        "    # test = pd.DataFrame(data=fitness_for_record)\n",
        "    # print(\"以下是原始数据\")\n",
        "    # print(test)\n",
        "    # test.to_csv(f'./{dsid}_raw_data.csv',encoding='gbk')\n",
        "\n",
        "    return acc_map\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # 正文代码----------------\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    dataset_acc = []\n",
        "    for dsid in all_dataset:\n",
        "        print(f\"Currently dataset is {dsid}\")\n",
        "        bs = 64\n",
        "        X, y, splits = get_UCR_data(dsid, return_split=False)\n",
        "        print(X.shape)\n",
        "        tfms  = [None, [Categorize()]]\n",
        "        dsets = TSDatasets(X, y, tfms=tfms, splits=splits)\n",
        "        \n",
        "        if dsid in dataset_with_nan:\n",
        "            batch_transforms = [TSStandardize(by_sample=True), Nan2Value()]\n",
        "            dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2], batch_tfms=batch_transforms)\n",
        "        else:\n",
        "            dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])\n",
        "\n",
        "\n",
        "        dataset_best_acc = DEA(dsid, dls)\n",
        "\n",
        "        # 作图\n",
        "        \n",
        "        x = np.linspace(1, GEN_MAX + 1, GEN_MAX)\n",
        "        plt.figure(figsize=(6, 4))# 新建一个图像，设置图像大小\n",
        "        plt.plot(x, dataset_best_acc, 'ro-', label='DEA')# 设置颜色、标记符号、线型、图例标签\n",
        "        plt.title(f'Differential Evolution for {dsid}', fontsize=15)# 标题\n",
        "        plt.xlim(0, GEN_MAX)# x轴范围\n",
        "        plt.ylim(0, 1)# y轴范围\n",
        "        plt.xlabel('Generation', fontsize=20)# x轴标签\n",
        "        plt.ylabel('Best fitness', fontsize=20)# y轴标签\n",
        "        plt.legend(loc='best')# 图例\n",
        "        if not os.path.exists(\"./svg\"):\n",
        "            os.makedirs(\"./svg\") # 如果不存在目录figure_save_path，则创建\n",
        "        plt.savefig(f'./svg/{dsid}.svg',format='svg')\n",
        "        plt.show()  \n",
        "\n",
        "        # 保存此时的raw_data\n",
        "        dataset_acc.append(dataset_best_acc)\n",
        "    forsave = pd.DataFrame(data=dataset_acc)\n",
        "    forsave.to_csv(\"./overall.csv\", encoding='gbk')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Release.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
